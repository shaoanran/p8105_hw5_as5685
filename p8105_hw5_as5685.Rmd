---
title: "p8105_hw5_as5685"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## load in data

```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

## Problem 1
#### Filling missing values 
```{r}
mean_function = function(x){
    
    if (is.numeric(x)) {
      x = replace_na(x,mean(x[!is.na(x)]))
    }else if (is.character(x)) {
      x = replace_na(x, "virginica")
    }
}
  
new_dataset = map_df( iris_with_missing, mean_function)
```


## Problem 2
#### Dataframe with all file names

```{r}
dataframe = tibble(
  
  file = list.files("./data")

  )

```

#### Tidy dataframe for all files. 

```{r, message=FALSE}
data_function = function(filename){
    
  read_csv(file = str_c("./data/", filename))
  
}

dataframe = 
  dataframe %>% 
  mutate(data = map(dataframe$file, data_function))
```


```{r}
unnest_data = 
dataframe %>% 
  unnest(data)

tidy_dataset = 
  pivot_longer(
    unnest_data,
    week_1:week_8,
    names_to = "week",
    values_to = "data"
  ) %>% 
  
mutate(
  file  = str_replace(file, ".csv$", "")
)  %>% 

  rename( participant = file)
```

#### spaghetti plot 
```{r}

spaghetti_plot =
  tidy_dataset %>% 
  separate(participant, into = c("arm","id"), sep = "_", remove =  FALSE ) %>% 
  mutate(
    arm = recode(arm, `con` = "control", `exp` = "experiment"),
  ) %>% 
  ggplot(aes(x = week, y = data, color = arm, group = participant)) +
  geom_line()

spaghetti_plot
```

* The data in experiment group generally are higher than control group for each week. with time, the data for experiment increases, but decrease for control group. 



First set the following design elements:

Fix n=30
Fix xi1 as draws from a standard Normal distribution
Fix β0=2
Fix σ2=50
Set β1=0. Generate 10000 datasets from the model
yi=β0+β1xi1+ϵi
with ϵi∼N[0,σ2]. 

For each dataset, save β̂ 1 and the p-value arising from a test of H:β1=0 using α=0.05. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of lm.


## Problem 3
```{r}
set.seed(1)
```

#### function

```{r}
sim_regression = function(n =30, beta0 = 2, beta1 = 0 ){
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1 ),
    y = beta0 +  beta1 * x + rnorm(n,0,50)
  )
  
  ls_fit = lm(y ~ x, data = sim_data) %>% 
    broom::tidy()
  
 tibble(
    beta1_hat =  ls_fit $estimate[2],
    p_value = ls_fit$p.value[2] 
  )
}
```

#### random results
```{r}
set.seed(1)
sim_results = 
  rerun(10000, sim_regression(30, 2, 0)) %>% 
  bind_rows() %>% 
  view()

```

Repeat the above for β1={1,2,3,4,5,6}, and complete the following:


#### try different betas
```{r}
sim_betas = 
tibble( betas = c(1,2,3,4,5,6)) %>% 
mutate(
  beta_lists = map(.x = betas, ~rerun(10000, sim_regression( beta1 = .x))),
  beta_dfs = map(beta_lists, bind_rows)
  ) %>% 
  select(-beta_lists) %>%
  unnest(beta_dfs) %>% 
  view()
```


#### proportion of times the null was rejected (the power of the test) on the y axis and the true value of β1 on the x axies.
```{r}
sim_beta_clean = 
  sim_betas %>% 
  group_by(betas) %>% 
  mutate(
    reject = ifelse(p_value <= 0.05, "yes","no")
  ) %>% 
  count(betas,reject) %>% 
  mutate(
    proportion = n/sum(n)
  ) %>% 
  filter(reject == "yes") %>% 
view()

plot_power_effect =
sim_beta_clean %>% 
ggplot(aes(x = betas, y = proportion)) + 
  geom_point() + geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Association between effect size and power",
    y = "Proportion of p-value <0.05",
    x = "True Beta"
  )
plot_power_effect
  
```

* The overall trend for the effect size and power is that power is increasing(the proportion of rejecting null hypothesis is becomes higher) with the increase of effect size(beta values).  


#### Plot for true betas and corresponding means of estimated betas as well asn estimated betas with p-values less than 0.05. 
```{r}
plot_beta = 
  sim_betas %>% 
  group_by(betas) %>% 
  mutate(
    estimatedbeta_mean = mean(beta1_hat)
  ) %>% 
  ggplot(aes(x = betas, y = estimatedbeta_mean)) + 
  geom_point() + geom_smooth(method = "lm", se = FALSE) +  
  labs(
    title = "Association between true betas and  corresponding estimated betas means",
    x = "True Betas",
    y = "Means of Estimated Betas"
  )
  
plot_beta



plot_rejectbeta =
  sim_betas %>% 
  filter(p_value <= 0.05) %>%
  group_by(betas) %>% 
  mutate(
    meanbeta = mean(beta1_hat)
  ) %>% 
  ggplot(aes(x = betas, y = meanbeta)) + 
  geom_point() + geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Association between true betas and means of estimated beta for rejecting Ho",
    x = "True Betas",
    y = "Mean of Estimated betas"
  )

plot_rejectbeta

```

* The sample average of beta across tests for which the null is rejected is not approximately equal to the true value of beta, since when p-value is greater than 0.05, the estimated betas are more close to zero. Therefore, if we exclude the p-values that are not rejecting the hypothesis, the mean of betas will be increased. 





















